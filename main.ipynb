{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First import libraries\n",
    "import numpy as np      #import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras.utils import np_utils\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()    #a dataset with 60,000 28x28 grayscale images ranging between 0-9\n",
    "                    #also contains 10,000 test images.\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_input_img(i):\n",
    "    plt.imshow(X_train[i], cmap = 'binary')\n",
    "    plt.title(y_train[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    plot_input_img(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process Images:\n",
    "\n",
    "# We normalize the images to a [0,1] range for easier processing\n",
    "X_train = X_train.astype(np.float32)/255       \n",
    "X_test = X_test.astype(np.float32)/255\n",
    "\n",
    "# Expand the dimensions of the images to (28,28,1) which is the dimension of our images\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "#convert classes to one-hot-vector, which allows the program to understand each value 0-9 in 'binary'\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#convolution neural network with standard 3x3 kernal size\n",
    "model.add(Conv2D(32, (3,3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), activation = 'relu'))\n",
    "model.add(MaxPool2D((2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#prevent overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(10, activation = \"softmax\"))  #10 number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Callbacks\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "es = EarlyStopping(monitor='val_acc', min_delta = 0.01, patience = 4, verbose = 1)\n",
    "\n",
    "#model checkpoint\n",
    "mc = ModelCheckpoint(\"./bestmodel.h5\", monitor = \"val_acc\", verbose = 1, save_best_only = True)\n",
    "\n",
    "#callback\n",
    "cb = [es,mc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1308/1313 [============================>.] - ETA: 0s - loss: 0.0046 - accuracy: 0.9983WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1313/1313 [==============================] - 13s 10ms/step - loss: 0.0047 - accuracy: 0.9983 - val_loss: 0.0665 - val_accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "his = model.fit(X_train, y_train, epochs = 1, validation_split = 0.3,callbacks =cb)\n",
    "\n",
    "model.save('./bestmodel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0560 - accuracy: 0.9916\n",
      " the model accuracy is 0.991599977016449 \n"
     ]
    }
   ],
   "source": [
    "model_S = tf.keras.models.load_model(\"C://Users//remyz//Documents//Coding Projects//ML_HandwrittenDigitRecognition//bestmodel.h5\")\n",
    "#for windows we changed \"\\\" to \"//\"\n",
    "\n",
    "score = model_S.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\" the model accuracy is {score[1]} \")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
